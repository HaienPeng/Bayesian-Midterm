---
title: "Midterm"
author: "Haien Peng"
format: pdf
editor: visual
---

## Model

为了解决多重共线性或是矩阵稀疏性问题，我们在一般线性模型中加入惩罚项，目标函数为 $min L(\beta)=\frac{1}{2N}||Y-X\beta||_2^2+\lambda\sum|\beta|$ ,这样使得系数能够被压缩到0从而自动筛选出重要的变量，而在Group Lasso中，为了表达具有相同特征的系数应该得到共同的保留或是丢弃选择， 我们根据特征将系数划分为 $G$ 个组，每组特征为 $\beta_g$, 维度为 $p_g$， 目标函数变为 $min L(\beta)=\frac{1}{2N}||Y-X\beta||_2^2+\lambda \sum^{G}_{g=1}\sqrt{p_g}||\beta_g||_2$, 正则化项是各组参数的 L2 范数的加权和, 在这个目标函数下，整组的参数大小会被惩罚，若一组参数的重要性较低，则整个组的系数会被压缩为0

## 数据

我研究使用的数据集来自 MovieLens 100K 数据集（MovieLens 100,000 Dataset），由美国明尼苏达大学（University of Minnesota）下属的 GroupLens Research Project 研究团队收集并整理。MovieLens 项目自 1990 年代起专注于协同过滤与推荐系统研究，该数据集是推荐算法研究中最经典、使用最广泛的公开数据集之一。我使用的数据集版本中包含了100,000 条评分记录（ratings）,943 位用户（users）,1,682 部电影（movies）,评分范围为 1 至 5,每位用户至少评价过 20 部电影。数据收集时间为 1997 年 9 月 19 日至 1998 年 4 月 22 日，来自 MovieLens 网站（movielens.umn.edu）上的真实用户交互记录。原始数据经过清洗，去除了评分过少或缺失用户信息的样本.电影信息包含了电影的基本元数据(title, release date)和19个类型变量(Action, Comedy, Drama 等).用户信息包含了用户的基本人口学特征如age, gender, occupation和zip code.\

在构建 Group LASSO 模型时，我根据 MovieLens 100K数据集中变量的语义关系与统计特征，对自变量进行了结构化分组.具体的分组方案如下:首先，在用户特征部分，我保留了性别与职业两个变量, 性别为二分类变量，用以描述男女用户在总体评分水平上的差异；职业为多分类变量,这些列共同表征用户的职业身份. 其次，在电影特征部分，电影的题材信息（Genres）被用作主要的内容层面变量,所以我将所有题材变量合并为一个整体的“题材主效应组. 最后，为了考察不同用户群体在不同类型电影上的偏好差异，我构造了两个交互项组），分别为：性别 × 题材组（Gender × Genre group），用于刻画男女用户在不同电影类型下的评分差异和职业 × 题材组（Occupation × Genre group），用于捕捉不同职业群体在不同题材上的偏好模式。\

## Experiments

首先我使用普通的Group LASSO回归来确定这五组是否设定合理.

```{r}
# ==========================================================
# Group LASSO on MovieLens 100K (five groups, frequentist)
# Groups: Gender, Occupation, Genre main effects,
#         Gender×Genre interactions, Occupation×Genre interactions
# ==========================================================

# ---- 0) Packages ----
# install.packages("gglasso")  # 如未安装，请先安装
suppressPackageStartupMessages({
  library(gglasso)
})

# ---- 1) Paths & Reading ----
data_dir <- "ml-100k"   
f_train <- file.path(data_dir, "u1.base")
f_test  <- file.path(data_dir, "u1.test")
f_user  <- file.path(data_dir, "u.user")
f_item  <- file.path(data_dir, "u.item")
f_genre <- file.path(data_dir, "u.genre")

# 训练集与测试集读取
train_ratings <- read.table(f_train, sep = "\t", header = FALSE,
                            col.names = c("user_id","item_id","rating","timestamp"))
test_ratings  <- read.table(f_test, sep = "\t", header = FALSE,
                            col.names = c("user_id","item_id","rating","timestamp"))

# u.user: user id | age | gender | occupation | zip (tab)
users <- read.table(f_user, sep = "|", header = FALSE, quote = "", col.names = c("user_id","age","gender","occupation","zip"))

# u.genre: name|index
genres_tbl <- read.table(f_genre, sep = "|", header = FALSE, quote = "", fill = TRUE,
                         col.names = c("genre","idx"))
genres_tbl <- genres_tbl[!is.na(genres_tbl$idx), ]
genres <- genres_tbl[order(genres_tbl$idx), "genre"]
# 确保正好 19 个：
stopifnot(length(genres) == 19)

# u.item: movie id | title | release date | video release date | IMDb URL | 19 genre flags
# 注意：用 '|' 作为分隔，标题里一般没有 '|'，safe
item_colnames <- c("movie_id","title","release_date","video_release_date","imdb_url", paste0("genre_", genres))
items <- read.table(f_item, sep = "|", header = FALSE, quote = "", fill = TRUE, stringsAsFactors = FALSE)
# 只取前 5 + 19 = 24 列（历史文件可能多列空白）
items <- items[, 1:(5 + length(genres)), drop = FALSE]
colnames(items) <- item_colnames

# ---- 2) Merge to one row per rating (user × item) ----
# rename for join
colnames(items)[1] <- "item_id"
# 构建训练数据 df_train
df_train <- merge(train_ratings, users, by = "user_id")
df_train <- merge(df_train, items, by = "item_id")

# 构建测试数据 df_test
df_test <- merge(test_ratings, users, by = "user_id")
df_test <- merge(df_test, items, by = "item_id")

# === 在构造完 df_train、df_test 之后追加 ===
set.seed(2025)
frac <- 0.02  # 保留 20% 训练样本，可改成 0.1 / 0.5 等
idx_sub <- sample.int(nrow(df_train), size = floor(frac * nrow(df_train)), replace = FALSE)
df_train_sub <- df_train[idx_sub, , drop = FALSE]

# === 在你现有的 “df <- df_train” 这一行的正下方，再追加这一行 ===
df <- df_train_sub



# ---- 3) Feature Engineering for the five groups ----
# (A) Gender group (binary: Male indicator; Female as baseline implicitly via no extra column)
#     为了简单起见，这里用单一一列：gender_M ∈ {0,1}

df$gender <- factor(df$gender, levels = c("F","M"))
gender_M <- as.integer(df$gender == "M")
X_gender <- matrix(gender_M, ncol = 1)
colnames(X_gender) <- "gender_M"

# (B) Occupation group (one-hot, 不加截距；保留全部职业列)
df$occupation <- factor(df$occupation)
X_occ <- model.matrix(~ occupation - 1, data = df)  # K 列
# 确认职业列数
K_occ <- ncol(X_occ)

# (C) Genre main-effect group (19 columns, 0/1)
genre_cols <- paste0("genre_", genres)
X_genre <- as.matrix(df[, genre_cols])
# 某些条目可能是字符，转数值
X_genre <- apply(X_genre, 2, function(z) as.numeric(as.character(z)))
storage.mode(X_genre) <- "numeric"
colnames(X_genre) <- paste0("genre_", genres)  # 再确认列名

# (D) Gender × Genre interaction group (19 columns)
#     逐列乘：每个题材 × gender_M
X_gxg <- sweep(X_genre, 1, gender_M, `*`)
colnames(X_gxg) <- paste0("gender_M_x_", colnames(X_genre))

# (E) Occupation × Genre interaction group (K_occ * 19 columns)
#     对每个题材列，与全部职业哑变量做元素乘
make_occxgenre <- function(genre_col_vec, occ_mat, gname) {
  out <- occ_mat * as.numeric(genre_col_vec)  # 按行广播
  colnames(out) <- paste0(colnames(occ_mat), "_x_", gname)
  out
}
occxgenre_list <- lapply(seq_len(ncol(X_genre)), function(j) {
  make_occxgenre(X_genre[, j], X_occ, colnames(X_genre)[j])
})
X_oxg <- do.call(cbind, occxgenre_list)  # N × (K_occ*19)

# ---- 4) Stack design matrix X & build group index gid ----
X <- cbind(X_gender, X_occ, X_genre, X_gxg, X_oxg)
y <- as.numeric(df$rating)

# 组大小
p_gender <- ncol(X_gender)           # 1
p_occ    <- ncol(X_occ)              # K_occ
p_genre  <- ncol(X_genre)            # 19
p_gxg    <- ncol(X_gxg)              # 19
p_oxg    <- ncol(X_oxg)              # K_occ * 19

# 组索引（整数向量，长度 = ncol(X)）
gid <- integer(ncol(X))
ptr <- 0
gid[(ptr+1):(ptr+p_gender)] <- 1;             ptr <- ptr + p_gender  # Gender group
gid[(ptr+1):(ptr+p_occ)]    <- 2;             ptr <- ptr + p_occ     # Occupation group
gid[(ptr+1):(ptr+p_genre)]  <- 3;             ptr <- ptr + p_genre   # Genre main-effect group
gid[(ptr+1):(ptr+p_gxg)]    <- 4;             ptr <- ptr + p_gxg     # Gender×Genre group
gid[(ptr+1):(ptr+p_oxg)]    <- 5;             ptr <- ptr + p_oxg     # Occupation×Genre group
stopifnot(ptr == ncol(X))

# ---- 5) Optional: standardize X and center y (gglasso 默认会标准化，但这里手动更可控) ----
# 为避免截距问题，这里不显式加入截距列；通过中心化 y 与 X 解决
# 检查每列方差
varX <- apply(X, 2, var, na.rm = TRUE)

# 找出方差为 0 的列
zero_var_cols <- which(varX == 0)

# 删除这些列
if (length(zero_var_cols) > 0) {
  cat("Removing", length(zero_var_cols), "constant columns with zero variance.\n")
  X <- X[, -zero_var_cols, drop = FALSE]
  gid <- gid[-zero_var_cols]  # 同步删掉对应的组索引
}

X_scaled <- scale(X, center = TRUE, scale = TRUE)
X_center_train  <- attr(X_scaled, "scaled:center")
X_scale_train   <- attr(X_scaled, "scaled:scale")
y_mean_train    <- mean(y)  # 预测时要加回这个均值
y_center <- as.numeric(scale(y, center = TRUE, scale = FALSE))

# ---- 6) Fit Group LASSO (least squares) + CV for lambda ----
set.seed(2025)
# 初步拟合（可画路径）
fit_gl <- gglasso(x = X_scaled, y = y_center, group = gid, loss = "ls", intercept = FALSE)

# 交叉验证选择 lambda
cv_gl  <- cv.gglasso(x = X_scaled, y = y_center, group = gid, loss = "ls", intercept = FALSE, nfolds = 5)
lambda_min <- cv_gl$lambda.min
lambda_1se <- cv_gl$lambda.1se


# ---- 7) Coefficients at chosen lambda & group selection summary ----
coef_min <- as.matrix(coef(cv_gl, s = "lambda.min"))[-1, , drop = FALSE]  # 去掉截距（第一行）
# 标记非零系数
nonzero <- abs(coef_min[,1]) > 1e-8

# 每组是否被选中（是否含有非零系数）
grp_names <- c("Gender", "Occupation", "Genre_main", "Gender×Genre", "Occupation×Genre")
grp_sizes <- c(p_gender, p_occ, p_genre, p_gxg, p_oxg)

group_selected <- tapply(nonzero, gid, any)
group_nonzero_counts <- tapply(nonzero, gid, sum)
```

```{r}
sel_df <- data.frame(
  group_id   = 1:5,
  group_name = grp_names,
  size       = grp_sizes,
  any_nonzero = as.logical(group_selected),
  nnz_in_group = as.integer(group_nonzero_counts)
)
print(sel_df, row.names = FALSE)
```

在构造职业与电影题材交互变量时，我发现部分职业类别在样本中未对特定题材影片进行评分，导致相应交互项在全样本中取值恒为0 (19项), 这些无方差的特征被我在标准化前删除，以避免数值问题。因此在交互项中模型认为一共有19项系数全为0.

```{r}

# ---- 9) 简单的CV曲线（可视化）----
plot(cv_gl)  # 如需查看CV误差随lambda变化
cat("log lambda.min =", log(lambda_min), "\n")
cat("log lambda.1se =", log(lambda_1se), "\n")
```

根据 5 折交叉验证，模型在 $log(\lambda)=-3.6684$ 处达到最小的预测误差。使用训练好的参数在测试集上做了测试，得到 $RMSE=1.1410, MAE=0.9469$

```{r}
# ==== 测试集：构造特征、按训练集方案对齐与标准化、评估 ====

# 为了最大程度少改动：下面单独为 df_test 复刻特征流程，
# 但所有训练端变量名保持不变；测试端使用 *_test 后缀。

df_t <- df_test  # 临时别名，避免覆盖训练用的 df

# (A) Gender group
df_t$gender <- factor(df_t$gender, levels = c("F","M"))
gender_M_test <- as.integer(df_t$gender == "M")
X_gender_test <- matrix(gender_M_test, ncol = 1)
colnames(X_gender_test) <- "gender_M"

# (B) Occupation group
df_t$occupation <- factor(df_t$occupation, levels = levels(df$occupation))  # 与训练集因子水平对齐
X_occ_test <- model.matrix(~ occupation - 1, data = df_t)
# 补齐可能缺失的职业列（测试集中可能没有某些职业）
missing_occ_cols <- setdiff(colnames(X_occ), colnames(X_occ_test))
if (length(missing_occ_cols) > 0) {
  add_zero <- matrix(0, nrow = nrow(X_occ_test), ncol = length(missing_occ_cols))
  colnames(add_zero) <- missing_occ_cols
  X_occ_test <- cbind(X_occ_test, add_zero)
}
# 按训练集列顺序重排
X_occ_test <- X_occ_test[, colnames(X_occ), drop = FALSE]

# (C) Genre main
X_genre_test <- as.matrix(df_t[, genre_cols])
X_genre_test <- apply(X_genre_test, 2, function(z) as.numeric(as.character(z)))
storage.mode(X_genre_test) <- "numeric"
colnames(X_genre_test) <- paste0("genre_", genres)

# (D) Gender × Genre
X_gxg_test <- sweep(X_genre_test, 1, gender_M_test, `*`)
colnames(X_gxg_test) <- paste0("gender_M_x_", colnames(X_genre_test))

# (E) Occupation × Genre
make_occxgenre_test <- function(genre_col_vec, occ_mat, gname) {
  out <- occ_mat * as.numeric(genre_col_vec)
  colnames(out) <- paste0(colnames(occ_mat), "_x_", gname)
  out
}
occxgenre_list_test <- lapply(seq_len(ncol(X_genre_test)), function(j) {
  make_occxgenre_test(X_genre_test[, j], X_occ_test, colnames(X_genre_test)[j])
})
X_oxg_test <- do.call(cbind, occxgenre_list_test)

# 叠加为完整设计矩阵（测试集）
X_test_full <- cbind(X_gender_test, X_occ_test, X_genre_test, X_gxg_test, X_oxg_test)

# 【关键对齐】删除与训练端相同的零方差列，并按训练端列顺序保持一致
if (length(zero_var_cols) > 0) {
  X_test <- X_test_full[, -zero_var_cols, drop = FALSE]
} else {
  X_test <- X_test_full
}

# 使用“训练集”的中心与尺度进行标准化
# 确保列名一致（防御性检查）
stopifnot(identical(colnames(X), colnames(X_test)))
X_test_centered <- sweep(X_test, 2, X_center_train, FUN = "-")
X_test_scaled   <- sweep(X_test_centered, 2, X_scale_train,  FUN = "/")

# 测试集标签（不中心化，用原始评分做评估）
y_test <- as.numeric(df_t$rating)

# 预测（cv_gl 基于中心化 y 训练的，因此预测值是“中心化刻度”）
y_pred_c_min  <- as.numeric(predict(cv_gl, newx = X_test_scaled, s = "lambda.min"))
y_pred_c_1se  <- as.numeric(predict(cv_gl, newx = X_test_scaled, s = "lambda.1se"))

# 加回训练集的 y 均值，得到原始刻度的预测
y_pred_min <- y_pred_c_min + y_mean_train
y_pred_1se <- y_pred_c_1se + y_mean_train

# 评估指标
rmse <- function(a,b) sqrt(mean((a-b)^2))
mae  <- function(a,b) mean(abs(a-b))

cat(sprintf("Test RMSE (lambda.min):  %.4f\n", rmse(y_test, y_pred_min)))
cat(sprintf("Test MAE  (lambda.min):  %.4f\n", mae(y_test,  y_pred_min)))
# cat(sprintf("Test RMSE (lambda.1se):  %.4f\n", rmse(y_test, y_pred_1se)))
# cat(sprintf("Test MAE  (lambda.1se):  %.4f\n", mae(y_test,  y_pred_1se)))
```

接下来使用Bayesian group LASSO对数据集进行建模与推断。模型假设每个观测 $y_i$ 服从正态分布，即 $y_i \sim N(X_i^{T}\beta, \sigma^2)$ 。为了体现变量分组的层级结构，我将所有特征划分为五个组：性别（Gender）、职业（Occupation）、电影类型（Genre）、性别与类型的交互项（Gender×Genre）以及职业与类型的交互项（Occupation×Genre）。对每个参数 $\beta$ 设定层级先验为 $\beta_p|\tau_{g(p)}$，其中 $g(p)$ 表示第 $p$ 个特征所属的组索引。各组参数 $\tau_g$ 指数分布先验 $\tau_g\sim Exponential(\lambda)$。噪声项的先验设为 $\sigma \sim Sturdent-t(3,0,2.5)$。

```{r}
# ==========================================================
# 8) Bayesian Group LASSO via Stan (接在现有代码之后，无需改前文变量)
# ==========================================================
suppressPackageStartupMessages({
  library(rstan)
})

rstan_options(auto_write = TRUE)
options(mc.cores = max(1L, parallel::detectCores() - 1L))

# ---- Prepare data for Stan ----
# 继续使用训练端已经标准化/中心化后的设计矩阵与响应：
#   X_scaled: 训练X（列已标准化）
#   y_center: 训练y（已中心化）
#   gid      : 每列所属组（1..5），已与 X 保持对齐
# 注意：若前面删除了 zero_var_cols，X 与 gid 也已同步删除，列名一致

N <- nrow(X_scaled)
P <- ncol(X_scaled)
G <- 5L
gid_vec <- as.integer(gid)  # 长度P，取值 1..5

# 超参数：lambda_B（group-lasso 强度，指数分布的 rate）
# 你可以先用 1.0 试跑，再按需要调大/调小（越大越强稀疏）
lambda_B <- 1.0

stan_data <- list(
  N = N,
  P = P,
  G = G,
  X = X_scaled,
  y = as.numeric(y_center),
  gid = gid_vec,
  lambda = lambda_B
)
```

由于直接采样该模型时，层级结构导致后验几何呈“漏斗”形，采样器易出现发散和树深超限问题，因此采用非中心化参数化（non-centered parameterization）以改善数值稳定性。该重参数化形式为 $z_p \sim N(0,1)$, 并令 $\beta_p=\tau_{g(p)}z_p$, 此时模型的生成过程可写为 $z_p\sim N(0,1), \tau_g \sim Exponential(\lambda), y_i \sim N(\sum X_{ip}\tau_{g(p)}z_{p},\sigma)$

```{r}
# ==========================================================
# 稳态版：非中心化 + 更保守的 NUTS 设置（追加即可）
# ==========================================================
suppressPackageStartupMessages({ library(rstan) })
rstan_options(auto_write = TRUE)
options(mc.cores = max(1L, parallel::detectCores() - 1L))

stan_code_ncp <- "
data {
  int<lower=1> N; int<lower=1> P; int<lower=1> G;
  matrix[N,P] X; vector[N] y;
  int<lower=1, upper=G> gid[P];
  real<lower=0> lambda;
}
parameters {
  vector[P] z;                   // 非中心化标准正态
  vector<lower=0>[G] tau;        // 组尺度
  real<lower=0> sigma;           // 噪声
}
transformed parameters {
  vector[P] beta;
  for (p in 1:P) beta[p] = tau[ gid[p] ] * z[p];
}
model {
  // 先验
  z ~ normal(0, 1);
  tau ~ exponential(lambda);
  sigma ~ student_t(3, 0, 2.5);

  // 似然
  y ~ normal(X * beta, sigma);
}
"

# 用与之前相同的 stan_data
stan_fit_ncp <- stan(model_code = stan_code_ncp, data = stan_data,
                     seed = 2025, chains = 4, iter = 1500, warmup = 750, init = 0,
                     control = list(adapt_delta = 0.999, max_treedepth = 15))

print(stan_fit_ncp, pars = c("sigma","tau[1]","tau[2]","tau[3]","tau[4]","tau[5]"))

# 预测（保持你现有流程与变量）
post_beta_ncp <- as.matrix(stan_fit_ncp, pars = "beta")
beta_mean_ncp <- colMeans(post_beta_ncp)
y_pred_c_ncp  <- as.numeric(X_test_scaled %*% beta_mean_ncp)
y_pred_ncp    <- y_pred_c_ncp + y_mean_train

rmse <- function(a,b) sqrt(mean((a-b)^2))
mae  <- function(a,b) mean(abs(a-b))

cat(sprintf("[Bayes-GroupLASSO-NCP] Test RMSE: %.4f\n", rmse(y_test, y_pred_ncp)))
cat(sprintf("[Bayes-GroupLASSO-NCP] Test MAE : %.4f\n", mae(y_test,  y_pred_ncp)))

# 诊断与稳定性检查
summary(stan_fit_ncp)$summary[, c("Rhat","n_eff")]
bayesplot::mcmc_trace(stan_fit_ncp, pars=c("tau[1]","tau[2]","tau[3]","tau[4]","tau[5]"))
bayesplot::mcmc_dens_overlay(stan_fit_ncp, pars=c("tau[1]","tau[5]"))

```

接下来我在研究中进一步扩展了模型的先验设定，具体地，我在原有的贝叶斯 Group LASSO 框架下，尝试了更换先验族的策略，以评估不同稀疏先验对模型推断与预测性能的影响。首先，我在 Group-Laplace 先验的基础上引入了超先验结构，令每个组的收缩强度参数 $\lambda_g$ 服从Gamma分布，即 $\lambda_g \sim Gamma(a_\lambda, b_\lambda)$, 从而允许数据自适应地调整不同组别的收缩程度。

```{r}
# ==========================================================
# A) Group-Laplace with Hyperprior on lambda_g (追加即可)
# ==========================================================
suppressPackageStartupMessages({ library(rstan) })
rstan_options(auto_write = TRUE)
options(mc.cores = max(1L, parallel::detectCores() - 1L))

stan_code_gl_hyper <- "
data {
  int<lower=1> N; int<lower=1> P; int<lower=1> G;
  matrix[N,P] X; vector[N] y; int<lower=1,upper=G> gid[P];
  real<lower=0> a_lambda;        // Gamma 形状
  real<lower=0> b_lambda;        // Gamma 率
}
parameters {
  vector[P] z;                   // 非中心化
  vector[G] log_tau;             // 在 log 尺度采样组尺度
  vector<lower=0>[G] lambda_g;   // 每组的收缩强度（带超先验）
  real<lower=0> sigma;
}
transformed parameters {
  vector<lower=0>[G] tau;        // 组尺度（正数）
  vector[P] beta;
  tau = exp(log_tau);
  for (p in 1:P) {
    beta[p] = tau[ gid[p] ] * z[p];
  }
}
model {
  // 超先验：lambda_g ~ Gamma(a_lambda, b_lambda)
  lambda_g ~ gamma(a_lambda, b_lambda);
  
  // 相当于：log p(log_tau_g | lambda_g) = log_tau_g - lambda_g * exp(log_tau_g)
  for (g in 1:G) target += log(lambda_g[g]) - lambda_g[g] * tau[g] + log_tau[g];

  // 其余先验
  z     ~ normal(0, 1);
  sigma ~ student_t(3, 0, 2.5);

  // 似然
  y ~ normal(X * beta, sigma);
}
"

# 组装数据（复用你已有 stan_data 的内容，但去掉 lambda，改成 a/b 超参）
stan_data_gl_hyper <- list(
  N = nrow(X_scaled), P = ncol(X_scaled), G = 5L,
  X = X_scaled, y = as.numeric(y_center), gid = as.integer(gid),
  a_lambda = 5.0,    # 你可以改：更大=更集中的先验
  b_lambda = 2.0
)

fit_gl_hyper <- stan(model_code = stan_code_gl_hyper, data = stan_data_gl_hyper,
                     seed = 2025, chains = 4, iter = 2000, warmup = 1000, init = 0,
                     control = list(adapt_delta = 0.9999, max_treedepth = 45))

# 预测与评估（与现有流程一致）
post_gl_hyper <- as.matrix(fit_gl_hyper, pars = "beta")
beta_mean_gl_hyper <- colMeans(post_gl_hyper)
y_pred_c_gl_hyper  <- as.numeric(X_test_scaled %*% beta_mean_gl_hyper)
y_pred_gl_hyper    <- y_pred_c_gl_hyper + y_mean_train

rmse <- function(a,b) sqrt(mean((a-b)^2))
mae  <- function(a,b) mean(abs(a-b))
cat(sprintf("[GL-Hyper] Test RMSE: %.4f\n", rmse(y_test, y_pred_gl_hyper)))
cat(sprintf("[GL-Hyper] Test MAE : %.4f\n", mae(y_test,  y_pred_gl_hyper)))

# 可选：看看学到的 lambda_g 与 tau
print(fit_gl_hyper, pars=c("lambda_g", "tau[1]", "tau[2]", "tau[3]", "tau[4]", "tau[5]"), probs=c(0.05,0.5,0.95))
mcmc_nuts_energy(nuts_params(fit_gl_hyper))
```

对 $\hat{R}$ 和 $ESS$ 进行诊断

```{r}
library(posterior)

# 全量概览
dr <- as_draws_df(fit_gl_hyper)
sum_all <- summarize_draws(dr)  # 含 rhat, ess_bulk, ess_tail

# 只看关键参数（组尺度 & 收缩强度 & sigma）
vars_key <- c("sigma", grep("^lambda_g\\[",   variables(dr), value = TRUE),
                         grep("^log_tau\\[",  variables(dr), value = TRUE),
                         grep("^tau\\[",      variables(dr), value = TRUE))  # 视你参数命名二选一：log_tau 或 tau
sum_key <- summarize_draws(dr, variables = vars_key)
head(sum_key, 10)

```
我将原有的 Laplace 族先验替换为Group Horseshoe（组马蹄）先验，其中每个系数的局部尺度 $\lambda_p$ 与组别全局尺度 $\tau_g$ 分别服从半柯西分布, 并采用非中心化参数化 $\beta_p=\tau_{g(p)}\lambda_pz_p$ 的形式实现推断.我比较了不同先验族在结构稀疏性、后验稳定性以及预测性能（RMSE/MAE）上的差异.

```{r}
# ==========================================================
# B) Group Horseshoe (non-centered) 追加版本
# ==========================================================
stan_code_group_hs <- "
data {
  int<lower=1> N; int<lower=1> P; int<lower=1> G;
  matrix[N,P] X; vector[N] y; int<lower=1,upper=G> gid[P];
}
parameters {
  vector[P] z;                        // 非中心化标准正态
  vector<lower=0>[G] tau;             // 组全局尺度（half-Cauchy）
  vector<lower=0>[P] lambda;          // 局部尺度（half-Cauchy）
  real<lower=0> sigma;
}
transformed parameters {
  vector[P] beta;
  // β = τ_group * λ_local * z
  for (p in 1:P) beta[p] = tau[ gid[p] ] * lambda[p] * z[p];
}
model {
  // half-Cauchy(0,1) 用截断 Cauchy 或 half-Student-t 等价写法
  // Stan 允许在 <lower=0> 下直接使用 cauchy(0,1)
  tau    ~ cauchy(0, 1);
  lambda ~ cauchy(0, 1);

  z     ~ normal(0, 1);
  sigma ~ student_t(3, 0, 2.5);

  y ~ normal(X * beta, sigma);
}
"

stan_data_group_hs <- list(
  N = nrow(X_scaled), P = ncol(X_scaled), G = 5L,
  X = X_scaled, y = as.numeric(y_center), gid = as.integer(gid)
)

fit_group_hs <- stan(model_code = stan_code_group_hs, data = stan_data_group_hs,
                     seed = 2025, chains = 4, iter = 2000, warmup = 1000, init = 0,
                     control = list(adapt_delta = 0.999, max_treedepth = 18))

post_group_hs <- as.matrix(fit_group_hs, pars = "beta")
beta_mean_group_hs <- colMeans(post_group_hs)
y_pred_c_group_hs  <- as.numeric(X_test_scaled %*% beta_mean_group_hs)
y_pred_group_hs    <- y_pred_c_group_hs + y_mean_train

cat(sprintf("[Group-Horseshoe] Test RMSE: %.4f\n", rmse(y_test, y_pred_group_hs)))
cat(sprintf("[Group-Horseshoe] Test MAE : %.4f\n", mae(y_test,  y_pred_group_hs)))

# 可选：查看组/局部尺度后验
print(fit_group_hs, pars=c("tau[1]","tau[2]","tau[3]","tau[4]","tau[5]","sigma"), probs=c(0.05,0.5,0.95))

```
